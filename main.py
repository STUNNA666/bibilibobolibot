# -*- coding: utf-8 -*-
import logging
import os
from pathlib import Path
from dotenv import load_dotenv
import google.generativeai as genai
from telegram import Update
from telegram.ext import Application, CommandHandler, MessageHandler, filters, ContextTypes

load_dotenv()

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO
)
logger = logging.getLogger(__name__)

TELEGRAM_BOT_TOKEN = os.getenv('TELEGRAM_BOT_TOKEN')
GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')

if not TELEGRAM_BOT_TOKEN:
    raise ValueError("TELEGRAM_BOT_TOKEN –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
if not GEMINI_API_KEY:
    raise ValueError("GEMINI_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-1.5-flash')

user_conversations = {}
MAX_HISTORY = 10

SYSTEM_PROMPT_FILE = Path(__file__).parent / 'system_prompt.txt'
try:
    with open(SYSTEM_PROMPT_FILE, 'r', encoding='utf-8') as f:
        SYSTEM_PROMPT = f.read().strip()
except FileNotFoundError:
    logger.warning(f"–§–∞–π–ª {SYSTEM_PROMPT_FILE} –Ω–µ –Ω–∞–π–¥–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–π –ø—Ä–æ–º–ø—Ç.")
    SYSTEM_PROMPT = "–¢—ã –ø–æ–ª–µ–∑–Ω—ã–π –ø–æ–º–æ—â–Ω–∏–∫. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º —è–∑—ã–∫–µ."


async def start(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_id = update.effective_user.id
    if user_id not in user_conversations:
        user_conversations[user_id] = []
    await update.message.reply_text(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –±–æ—Ç —Å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π Google Gemini.\n"
        "–ù–∞–ø–∏—à–∏ –º–Ω–µ –ª—é–±–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, –∏ —è –ø–æ–º–æ–≥—É —Ç–µ–±–µ! ü§ñ\n"
        "–Ø –±—É–¥—É –∑–∞–ø–æ–º–∏–Ω–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞—à–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞."
    )


async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    help_text = """
üìñ –î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:
/start - –ó–∞–ø—É—Å—Ç–∏—Ç—å –±–æ—Ç–∞
/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç—É —Å–ø—Ä–∞–≤–∫—É
/prompt - –ü–æ–∫–∞–∑–∞—Ç—å —Ç–µ–∫—É—â–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
/clear - –û—á–∏—Å—Ç–∏—Ç—å –∏—Å—Ç–æ—Ä–∏—é –¥–∏–∞–ª–æ–≥–∞

–Ø –∑–∞–ø–æ–º–∏–Ω–∞—é –∫–æ–Ω—Ç–µ–∫—Å—Ç –Ω–∞—à–µ–≥–æ –¥–∏–∞–ª–æ–≥–∞ –∏ –∏—Å–ø–æ–ª—å–∑—É—é –µ–≥–æ –¥–ª—è –æ—Ç–≤–µ—Ç–æ–≤!
    """
    await update.message.reply_text(help_text)


async def show_prompt(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    await update.message.reply_text(f"üìù –¢–µ–∫—É—â–∏–π —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç:\n\n{SYSTEM_PROMPT}")


async def clear_context(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_id = update.effective_user.id
    if user_id in user_conversations:
        user_conversations[user_id] = []
        await update.message.reply_text("üóëÔ∏è –ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞ –æ—á–∏—â–µ–Ω–∞!")
    else:
        await update.message.reply_text("–ò—Å—Ç–æ—Ä–∏—è –±—ã–ª–∞ —É–∂–µ –ø—É—Å—Ç–∞.")


async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    user_message = update.message.text
    user_id = update.effective_user.id
    
    if user_id not in user_conversations:
        user_conversations[user_id] = []
    
    logger.info(f"–°–æ–æ–±—â–µ–Ω–∏–µ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {user_message}")
    
    try:
        await update.message.chat.send_action("typing")
        
        user_conversations[user_id].append(f"–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: {user_message}")
        
        history = "\n".join(user_conversations[user_id][-MAX_HISTORY:])
        
        prompt = f"{SYSTEM_PROMPT}\n\n–ò—Å—Ç–æ—Ä–∏—è –¥–∏–∞–ª–æ–≥–∞:\n{history}"
        
        response = model.generate_content(prompt)
        ai_response = response.text
        
        user_conversations[user_id].append(f"–ê—Å—Å–∏—Å—Ç–µ–Ω—Ç: {ai_response}")
        
        if len(user_conversations[user_id]) > MAX_HISTORY * 2:
            user_conversations[user_id] = user_conversations[user_id][-MAX_HISTORY * 2:]
        
        logger.info(f"–û—Ç–≤–µ—Ç –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è {user_id}: {ai_response[:100]}...")
        
        await update.message.reply_text(ai_response)
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {e}")
        await update.message.reply_text(
            f"‚ùå –ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞: {str(e)}\n"
            "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø–æ–ø—Ä–æ–±—É–π—Ç–µ —Å–Ω–æ–≤–∞."
        )


async def error_handler(update: Update, context: ContextTypes.DEFAULT_TYPE) -> None:
    logger.error(f"–û—à–∏–±–∫–∞: {context.error}")


def main() -> None:
    logger.info("–ó–∞–ø—É—Å–∫ Telegram –±–æ—Ç–∞...")
    
    application = Application.builder().token(TELEGRAM_BOT_TOKEN).build()
    
    application.add_handler(CommandHandler("start", start))
    application.add_handler(CommandHandler("help", help_command))
    application.add_handler(CommandHandler("prompt", show_prompt))
    application.add_handler(CommandHandler("clear", clear_context))
    
    application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))
    
    application.add_error_handler(error_handler)
    
    logger.info("–ë–æ—Ç –∑–∞–ø—É—â–µ–Ω –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
    application.run_polling()


if __name__ == '__main__':
    main()
