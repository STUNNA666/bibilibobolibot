import os
import logging
import asyncio
import sqlite3
from google import genai
from aiogram import Bot, Dispatcher, types
from aiogram.filters import Command
from dotenv import load_dotenv

# --- –ó–ê–ì–†–£–ó–ö–ê –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–ò ---
load_dotenv()
logging.basicConfig(level=logging.INFO)

BOT_TOKEN = os.getenv("BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")

# –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–π
if not BOT_TOKEN or not GEMINI_API_KEY:
    logging.error("‚ùå –û–®–ò–ë–ö–ê: –ö–ª—é—á–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã –≤ .env! –ü—Ä–æ–≤–µ—Ä—å –Ω–∞–∑–≤–∞–Ω–∏—è: BOT_TOKEN –∏ GEMINI_API_KEY")
    exit()

# –ß–∏—Ç–∞–µ–º —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç
try:
    with open('system_prompt.txt', 'r', encoding='utf-8') as f:
        SYSTEM_PROMPT = f.read()
    logging.info("‚úÖ –°–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –∑–∞–≥—Ä—É–∂–µ–Ω.")
except FileNotFoundError:
    logging.error("‚ùå –û–®–ò–ë–ö–ê: –§–∞–π–ª system_prompt.txt –Ω–µ –Ω–∞–π–¥–µ–Ω.")
    exit()

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –∫–ª–∏–µ–Ω—Ç–∞ (–Ω–æ–≤–∞—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∞)
client = genai.Client(api_key=GEMINI_API_KEY)

# --- –í–´–ë–û–† –ú–û–î–ï–õ–ò ---
# –í 2025 –≥–æ–¥—É gemini-1.5-flash –º–æ–∂–µ—Ç –±—ã—Ç—å —É—Å—Ç–∞—Ä–µ–≤—à–µ–π.
# –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–∫—Ç—É–∞–ª—å–Ω—É—é –≤–µ—Ä—Å–∏—é 2.0.
MODEL_NAME = "gemini-2.5-flash"

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π (–≤—ã–≤–æ–¥–∏—Ç –≤ –∫–æ–Ω—Å–æ–ª—å –ø—Ä–∏ —Å—Ç–∞—Ä—Ç–µ)
def check_available_models():
    try:
        logging.info("üîç –ü—Ä–æ–≤–µ—Ä—è—é –¥–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏...")
        # –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π
        models = client.models.list()
        # –ò—â–µ–º –º–æ–¥–µ–ª–∏, —Å–æ–¥–µ—Ä–∂–∞—â–∏–µ 'gemini' –∏ 'flash'
        available = [m.name for m in models if "gemini" in m.name]
        
        logging.info(f"üìã –î–æ—Å—Ç—É–ø–Ω—ã–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —Ç–≤–æ–µ–≥–æ –∫–ª—é—á–∞: {available}")
        
        # –ï—Å–ª–∏ –Ω–∞—à–µ–π –º–æ–¥–µ–ª–∏ –Ω–µ—Ç –≤ —Å–ø–∏—Å–∫–µ, –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–∞–µ–º
        full_model_name = f"models/{MODEL_NAME}"
        if not any(MODEL_NAME in m for m in available):
            logging.warning(f"‚ö†Ô∏è –í–ù–ò–ú–ê–ù–ò–ï: –ú–æ–¥–µ–ª—å {MODEL_NAME} –º–æ–∂–µ—Ç –Ω–µ —Å—Ä–∞–±–æ—Ç–∞—Ç—å. –ü–æ–ø—Ä–æ–±—É–π –æ–¥–Ω—É –∏–∑ —Å–ø–∏—Å–∫–∞ –≤—ã—à–µ!")
            
    except Exception as e:
        logging.error(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π (–Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ): {e}")

bot = Bot(token=BOT_TOKEN)
dp = Dispatcher()

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ë–î
def init_db():
    conn = sqlite3.connect('edip_history.db')
    cur = conn.cursor()
    cur.execute('''
        CREATE TABLE IF NOT EXISTS chat_log (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER,
            username TEXT,
            user_input TEXT,
            full_prompt_sent TEXT, 
            ai_response TEXT,
            timestamp DATETIME DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    conn.commit()
    conn.close()
    logging.info("‚úÖ –ë–∞–∑–∞ –¥–∞–Ω–Ω—ã—Ö –ø–æ–¥–∫–ª—é—á–µ–Ω–∞.")

@dp.message(Command("start"))
async def cmd_start(message: types.Message):
    await message.answer(
        "üëã **–ö–æ—Ä–Ω–µ–≤–æ–π –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä –ï–î–ò–ü –Ω–∞ —Å–≤—è–∑–∏.**\n\n"
        "–Ø –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ. –ò—Å–ø–æ–ª—å–∑—É—é –ø—Ä–æ—Ç–æ–∫–æ–ª: `Gemini 2.0`.\n"
        "–í–≤–µ–¥–∏—Ç–µ –≤–≤–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –æ –±–∏–∑–Ω–µ—Å–µ."
    )

@dp.message()
async def process_message(message: types.Message):
    user_text = message.text
    
    await bot.send_chat_action(chat_id=message.chat.id, action="typing")
    
    full_prompt = f"{SYSTEM_PROMPT}\n\n--- –í–•–û–î–ù–´–ï –î–ê–ù–ù–´–ï –û–¢ –ü–û–õ–¨–ó–û–í–ê–¢–ï–õ–Ø ---\n{user_text}"
    
    try:
        # –ó–∞–ø—Ä–æ—Å –∫ Gemini
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=full_prompt
        )
        
        ai_answer = response.text
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        conn = sqlite3.connect('edip_history.db')
        cur = conn.cursor()
        cur.execute(
            "INSERT INTO chat_log (user_id, username, user_input, full_prompt_sent, ai_response) VALUES (?, ?, ?, ?, ?)",
            (message.from_user.id, message.from_user.username, user_text, full_prompt, ai_answer)
        )
        conn.commit()
        conn.close()
        
        await message.answer(ai_answer, parse_mode="Markdown")
        
    except Exception as e:
        logging.error(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        error_msg = str(e)
        if "404" in error_msg:
            await message.answer(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏: `{MODEL_NAME}` –Ω–µ –Ω–∞–π–¥–µ–Ω–∞. –ü–æ—Å–º–æ—Ç—Ä–∏—Ç–µ –≤ –∫–æ–Ω—Å–æ–ª—å —Å–µ—Ä–≤–µ—Ä–∞, —Ç–∞–º –≤—ã–≤–µ–¥–µ–Ω —Å–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π.")
        else:
            await message.answer("‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ.")

async def main():
    init_db()
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–æ–¥–µ–ª–∏ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º
    check_available_models()
    await dp.start_polling(bot)

if __name__ == "__main__":
    asyncio.run(main())